# CS-6263-HW3


This work is based on LLama 2.7B and Phi-2.
The models were trained on this dataset python-codes-25k


Requirements 
Python 3.7
Pytorch 2.9
Transformers 4.4
numpy
 install
 !pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7
 !pip install sacrebleu rouge-score bert-score
 Google colab was used in training on GPU V100
 
